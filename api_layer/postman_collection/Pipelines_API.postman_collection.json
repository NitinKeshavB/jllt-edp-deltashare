{
	"info": {
		"_postman_id": "f1e2d3c4-b5a6-4c7d-8e9f-0a1b2c3d4e5f",
		"name": "Delta Share - Pipelines API",
		"description": "Complete API collection for managing Delta Live Tables (DLT) pipelines with comprehensive pre-creation validations",
		"schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
	},
	"variable": [
		{
			"key": "base_url",
			"value": "https://your-api.azurewebsites.net",
			"type": "string"
		},
		{
			"key": "workspace_url",
			"value": "https://adb-xxxx.azuredatabricks.net",
			"type": "string"
		},
		{
			"key": "subscription_key",
			"value": "your-subscription-key-here",
			"type": "string"
		},
		{
			"key": "pipeline_name",
			"value": "test_pipeline",
			"type": "string"
		}
	],
	"item": [
		{
			"name": "List All Pipelines",
			"request": {
				"method": "GET",
				"header": [
					{
						"key": "X-Workspace-URL",
						"value": "{{workspace_url}}",
						"type": "text"
					},
					{
						"key": "Ocp-Apim-Subscription-Key",
						"value": "{{subscription_key}}",
						"type": "text"
					}
				],
				"url": {
					"raw": "{{base_url}}/pipelines?page_size=100&search_string=",
					"host": ["{{base_url}}"],
					"path": ["pipelines"],
					"query": [
						{
							"key": "page_size",
							"value": "100",
							"description": "Maximum number of pipelines to return (default: 100)"
						},
						{
							"key": "search_string",
							"value": "",
							"description": "Optional search string to filter pipelines by name"
						}
					]
				},
				"description": "List all DLT pipelines with optional name filtering. Returns pipeline details including ID, name, state, and configuration. Use search_string to filter by pipeline name."
			},
			"response": []
		},
		{
			"name": "Get Pipeline by Name",
			"request": {
				"method": "GET",
				"header": [
					{
						"key": "X-Workspace-URL",
						"value": "{{workspace_url}}",
						"type": "text"
					},
					{
						"key": "Ocp-Apim-Subscription-Key",
						"value": "{{subscription_key}}",
						"type": "text"
					}
				],
				"url": {
					"raw": "{{base_url}}/pipelines/{{pipeline_name}}",
					"host": ["{{base_url}}"],
					"path": ["pipelines", "{{pipeline_name}}"]
				},
				"description": "Get details of a specific DLT pipeline by name. Returns full pipeline configuration including catalog, target, libraries, and settings.\n\nValidation: Pipeline name is required and cannot be empty, contain only whitespace, or have leading/trailing spaces."
			},
			"response": []
		},
		{
			"name": "Create Pipeline",
			"request": {
				"method": "POST",
				"header": [
					{
						"key": "X-Workspace-URL",
						"value": "{{workspace_url}}",
						"type": "text"
					},
					{
						"key": "Content-Type",
						"value": "application/json",
						"type": "text"
					}
				],
				"body": {
					"mode": "raw",
					"raw": "{\n  \"target_catalog_name\": \"my_catalog\",\n  \"target_schema_name\": \"my_schema\",\n  \"configuration\": {\n    \"pipelines.source_table\": \"catalog.schema.source_table\",\n    \"pipelines.keys\": \"id\",\n    \"pipelines.target_table\": \"target_table_name\",\n    \"pipelines.scd_type\": \"2\"\n  },\n  \"notifications_list\": [\n    \"user@example.com\",\n    \"data-engineering-team\"\n  ],\n  \"tags\": {\n    \"environment\": \"production\",\n    \"owner\": \"data-team\"\n  },\n  \"serverless\": true\n}",
					"options": {
						"raw": {
							"language": "json"
						}
					}
				},
				"url": {
					"raw": "{{base_url}}/pipelines/{{pipeline_name}}",
					"host": ["{{base_url}}"],
					"path": ["pipelines", "{{pipeline_name}}"]
				},
				"description": "Create a new Delta Live Tables (DLT) pipeline with comprehensive automated validations.\n\n**Required fields:**\n- target_catalog_name: Unity Catalog name\n- target_schema_name: Target schema name\n- configuration.pipelines.source_table: Source table (catalog.schema.table)\n- configuration.pipelines.keys: Primary key column(s)\n- configuration.pipelines.target_table: Target table name\n- configuration.pipelines.scd_type: SCD type (1 or 2)\n\n**Optional fields:**\n- notifications_list: Email addresses and/or AD group names\n- tags: Key-value pairs for pipeline metadata\n- serverless: Enable serverless compute (default: true)\n\n**Pre-creation validations performed automatically:**\n\n1. **Target Catalog**: Checks if target catalog exists. If not, creates it automatically and grants ALL PRIVILEGES to the service principal.\n\n2. **Target Schema**: Checks if target schema exists within the catalog. If not, creates it automatically.\n\n3. **Source Table**: Validates that source table exists, is accessible, and has Change Data Feed (CDF) enabled. If CDF is not enabled, attempts to enable it automatically using SQL warehouse.\n\n4. **Pipeline Keys**: Verifies that all specified keys exist as columns in the source table using case-insensitive matching.\n\n**System automatically sets:**\n- pipelines.sequence_by = \"_commit_version\"\n- pipelines.delete_expr = \"_change_type = 'delete'\"\n\n**Validation requirements:**\n- Pipeline name cannot have leading/trailing spaces or be empty\n- Source table must exist and be accessible\n- All keys must be valid column names in the source table\n- Target catalog and schema will be created if they don't exist\n\n**Note:** If CDF cannot be enabled automatically (e.g., no SQL warehouse available), the creation will fail with an appropriate error message."
			},
			"response": []
		},
		{
			"name": "Delete Pipeline",
			"request": {
				"method": "DELETE",
				"header": [
					{
						"key": "X-Workspace-URL",
						"value": "{{workspace_url}}",
						"type": "text"
					},
					{
						"key": "Ocp-Apim-Subscription-Key",
						"value": "{{subscription_key}}",
						"type": "text"
					}
				],
				"url": {
					"raw": "{{base_url}}/pipelines/{{pipeline_name}}",
					"host": ["{{base_url}}"],
					"path": ["pipelines", "{{pipeline_name}}"]
				},
				"description": "Permanently delete a DLT pipeline by name. User must be the owner. This will remove all pipeline configurations and stop any running updates.\n\nValidation: Pipeline name cannot have leading/trailing spaces or be empty."
			},
			"response": []
		},
		{
			"name": "Update Pipeline Configuration",
			"request": {
				"method": "PUT",
				"header": [
					{
						"key": "X-Workspace-URL",
						"value": "{{workspace_url}}",
						"type": "text"
					},
					{
						"key": "Content-Type",
						"value": "application/json",
						"type": "text"
					}
				],
				"body": {
					"mode": "raw",
					"raw": "{\n  \"pipelines.keys\": \"id,timestamp\",\n  \"pipelines.target_table\": \"updated_target_table\"\n}",
					"options": {
						"raw": {
							"language": "json"
						}
					}
				},
				"url": {
					"raw": "{{base_url}}/pipelines/{{pipeline_name}}/configuration",
					"host": ["{{base_url}}"],
					"path": ["pipelines", "{{pipeline_name}}", "configuration"]
				},
				"description": "Update DLT pipeline configuration (partial update for keys and target_table only).\n\n**Updateable fields:**\n- pipelines.keys: Primary key column(s) - single column or comma-separated list\n- pipelines.target_table: Target table name\n\n**Keys Validation:**\nWhen updating pipelines.keys, the API automatically validates that all specified keys exist as columns in the source table using case-insensitive matching. If any keys are invalid, the update will fail with a clear error message listing the invalid keys.\n\n**Immutable fields (cannot be updated after creation):**\n- pipelines.source_table: Source table reference\n- pipelines.scd_type: SCD type (1 or 2)\n\n**System automatically maintains:**\n- pipelines.sequence_by = \"_commit_version\"\n- pipelines.delete_expr = \"_change_type = 'delete'\"\n\nAll other pipeline settings (catalog, libraries, storage, etc.) are preserved.\n\n**Examples:**\n- Update only keys: {\"pipelines.keys\": \"new_key_column\"}\n- Update only target_table: {\"pipelines.target_table\": \"new_table_name\"}\n- Update both: {\"pipelines.keys\": \"id,timestamp\", \"pipelines.target_table\": \"updated_table\"}\n\n**Note:** Provide at least one field to update. Pipeline name cannot have leading/trailing spaces."
			},
			"response": []
		},
		{
			"name": "Update Pipeline Libraries",
			"request": {
				"method": "PUT",
				"header": [
					{
						"key": "X-Workspace-URL",
						"value": "{{workspace_url}}",
						"type": "text"
					},
					{
						"key": "Content-Type",
						"value": "application/json",
						"type": "text"
					}
				],
				"body": {
					"mode": "raw",
					"raw": "{\n  \"library_path\": \"/Workspace/Shared/.bundle/dab_project/prod/files/citibike_etl/dlt/pattern/pattern-load.py\",\n  \"root_path\": \"/Workspace/Shared/.bundle/dab_project/prod/files\"\n}",
					"options": {
						"raw": {
							"language": "json"
						}
					}
				},
				"url": {
					"raw": "{{base_url}}/pipelines/{{pipeline_name}}/libraries",
					"host": ["{{base_url}}"],
					"path": ["pipelines", "{{pipeline_name}}", "libraries"]
				},
				"description": "Update DLT pipeline library path and/or root folder path.\n\n**You can update:**\n- library_path: Path to notebook or Python file (must start with /Workspace/ or /Repos/ and end with .py)\n- root_path: Root folder path (must start with /Workspace/ or /Repos/)\n- Both fields together\n\nAt least one field must be provided.\n\nAll other pipeline settings (configuration, catalog, target, storage, etc.) are preserved."
			},
			"response": []
		},
		{
			"name": "Add Notification Recipients",
			"request": {
				"method": "PUT",
				"header": [
					{
						"key": "X-Workspace-URL",
						"value": "{{workspace_url}}",
						"type": "text"
					},
					{
						"key": "Content-Type",
						"value": "application/json",
						"type": "text"
					}
				],
				"body": {
					"mode": "raw",
					"raw": "{\n  \"notifications_list\": [\n    \"new-user@example.com\",\n    \"data-team\",\n    \"monitoring-alerts\"\n  ]\n}",
					"options": {
						"raw": {
							"language": "json"
						}
					}
				},
				"url": {
					"raw": "{{base_url}}/pipelines/{{pipeline_name}}/notifications/add",
					"host": ["{{base_url}}"],
					"path": ["pipelines", "{{pipeline_name}}", "notifications", "add"]
				},
				"description": "Add notification recipients to a DLT pipeline. This ADDS to existing notifications (does not replace them).\n\n**The notifications list can include:**\n- Email addresses (e.g., user@example.com)\n- AD group names (e.g., data-engineering-team)\n\nIf a recipient already exists, it will not be duplicated. The response will indicate which recipients were newly added vs. already existing.\n\n**Notifications are sent for:**\n- on-update-failure\n- on-update-fatal-failure\n- on-update-success\n- on-flow-failure"
			},
			"response": []
		},
		{
			"name": "Remove Notification Recipients",
			"request": {
				"method": "PUT",
				"header": [
					{
						"key": "X-Workspace-URL",
						"value": "{{workspace_url}}",
						"type": "text"
					},
					{
						"key": "Content-Type",
						"value": "application/json",
						"type": "text"
					}
				],
				"body": {
					"mode": "raw",
					"raw": "{\n  \"notifications_list\": [\n    \"old-user@example.com\",\n    \"deprecated-team\"\n  ]\n}",
					"options": {
						"raw": {
							"language": "json"
						}
					}
				},
				"url": {
					"raw": "{{base_url}}/pipelines/{{pipeline_name}}/notifications/remove",
					"host": ["{{base_url}}"],
					"path": ["pipelines", "{{pipeline_name}}", "notifications", "remove"]
				},
				"description": "Remove specific notification recipients from a DLT pipeline.\n\nAt least one notification recipient must remain after removal. The response will indicate which recipients were removed vs. not found.\n\n**The notifications list can include:**\n- Email addresses (e.g., user@example.com)\n- AD group names (e.g., data-engineering-team)\n\nIf a recipient doesn't exist in the current list, it will be listed as 'not_found' in the response but the operation will still succeed for other recipients."
			},
			"response": []
		},
		{
			"name": "Update Continuous Mode",
			"request": {
				"method": "PUT",
				"header": [
					{
						"key": "X-Workspace-URL",
						"value": "{{workspace_url}}",
						"type": "text"
					},
					{
						"key": "Content-Type",
						"value": "application/json",
						"type": "text"
					}
				],
				"body": {
					"mode": "raw",
					"raw": "{\n  \"continuous\": true\n}",
					"options": {
						"raw": {
							"language": "json"
						}
					}
				},
				"url": {
					"raw": "{{base_url}}/pipelines/{{pipeline_name}}/continuous",
					"host": ["{{base_url}}"],
					"path": ["pipelines", "{{pipeline_name}}", "continuous"]
				},
				"description": "Update the continuous mode of a DLT pipeline.\n\n**Continuous mode options:**\n\n**continuous=true:** Pipeline runs continuously, processing data as it arrives\n- Best for streaming data and real-time processing\n- Lower latency but consumes cluster resources continuously\n- Pipeline stays active\n\n**continuous=false:** Pipeline runs in triggered mode\n- Best for batch processing and scheduled jobs\n- Only runs when manually triggered or scheduled\n- More cost-effective for periodic data processing\n- Higher latency but better resource utilization"
			},
			"response": []
		},
		{
			"name": "Full Refresh Pipeline",
			"request": {
				"method": "POST",
				"header": [
					{
						"key": "X-Workspace-URL",
						"value": "{{workspace_url}}",
						"type": "text"
					},
					{
						"key": "Ocp-Apim-Subscription-Key",
						"value": "{{subscription_key}}",
						"type": "text"
					}
				],
				"url": {
					"raw": "{{base_url}}/pipelines/{{pipeline_name}}/full-refresh",
					"host": ["{{base_url}}"],
					"path": ["pipelines", "{{pipeline_name}}", "full-refresh"]
				},
				"description": "Perform a full refresh of a DLT pipeline. This will recompute all tables from scratch.\n\n**A full refresh will:**\n- Drop all existing data in target tables\n- Re-read all source data\n- Rebuild all derived tables\n- Recompute all aggregations\n\n**Behavior:**\n- If pipeline is IDLE/STOPPED: Full refresh starts immediately\n- If pipeline is RUNNING/STARTING/STOPPING: Pipeline is stopped first, then full refresh starts\n- Maximum wait time: 10 minutes (600 seconds) for pipeline to stop\n\n**Use cases:**\n- Schema changes requiring data rebuild\n- Data quality issues requiring complete reprocessing\n- Testing with fresh data\n- Recovering from corrupted state\n\n**Warning:** This operation will DELETE all existing data in target tables. The pipeline will be unavailable during the refresh."
			},
			"response": []
		}
	]
}
